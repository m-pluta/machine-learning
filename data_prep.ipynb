{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Image handling\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reproducability\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we establish the directory to where our data is stored, and where we ultimately want to store our cleaned, preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_DIR = 'chinese-handwriting-recognition-hsk-1/chinese-handwriting/'\n",
    "\n",
    "INIT_TRAIN_DIR = os.path.join(INIT_DIR, 'CASIA-HWDB_Train/Train/')\n",
    "INIT_TEST_DIR = os.path.join(INIT_DIR, 'CASIA-HWDB_Test/Test/')\n",
    "\n",
    "DIR = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets have a look at how many data classes we have in the dataset. The dataset has been split into test and train already so lets check how many classes we have in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classes_train = os.listdir(INIT_TRAIN_DIR)\n",
    "image_classes_test = os.listdir(INIT_TEST_DIR)\n",
    "print(len(image_classes_train), image_classes_train)\n",
    "print(len(image_classes_test), image_classes_test)\n",
    "\n",
    "if image_classes_train == image_classes_test:\n",
    "    print('The same classes are in each folder')\n",
    "    # image_classes = ['零', '一', '二']\n",
    "    # image_classes = ['零', '一', '二', '三', '四', '五', '六', '七', '八', '九', '十']\n",
    "    # image_classes = image_classes_train[:20]\n",
    "    image_classes = image_classes_train\n",
    "else:\n",
    "    print('The two folders contain different classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets combine the the train and test data into one directory for simplicity.\n",
    "\n",
    "We start by creating a new directory for our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old data\n",
    "if os.path.exists(DIR):\n",
    "    shutil.rmtree(DIR)\n",
    "    \n",
    "#Create the new directory\n",
    "os.mkdir(DIR)\n",
    "for image_class in image_classes:\n",
    "    path = os.path.join(DIR, image_class)\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the train and test data into one directory. This is specified by the `DIR` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in image_classes:\n",
    "    images = []\n",
    "\n",
    "    # Fetch images from train dir\n",
    "    train_path = os.path.join(INIT_TRAIN_DIR, image_class)\n",
    "    images += [os.path.join(train_path, file) for file in os.listdir(train_path)]\n",
    "\n",
    "    # Fetch images from test dir\n",
    "    test_path = os.path.join(INIT_TEST_DIR, image_class)\n",
    "    images += [os.path.join(test_path, file) for file in os.listdir(test_path)]\n",
    "\n",
    "    # Iterate over the splits and images and copy them to the data directory\n",
    "    for i, image in enumerate(images):\n",
    "        new_filename = f\"{i+1}.png\"\n",
    "        destination_path = os.path.join(DIR, image_class, new_filename)\n",
    "        shutil.copy(image, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets iterate through all the images and and confirm they are all `.png` and black & white "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each subdirectory and file in the directory\n",
    "for subdir, dirs, images in os.walk(DIR):\n",
    "    for image in images:\n",
    "        if image.lower().endswith('.png'):\n",
    "            file_path = os.path.join(subdir, image)\n",
    "\n",
    "            with Image.open(file_path) as img:\n",
    "                if img.mode != 'L':\n",
    "                    print(f\"{file_path} is not grayscale.\")\n",
    "        else:\n",
    "            print(\"Not a png file: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's iterate through all the images and check if any have an aspect ratio that is not 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sizes = []\n",
    "\n",
    "# Iterate through all the images and check if any do not have a 1:1 aspect ratio\n",
    "for subdir, dirs, images in os.walk(DIR):\n",
    "    for image in images:\n",
    "        file_path = os.path.join(subdir, image)\n",
    "        with Image.open(file_path) as img:\n",
    "            image_sizes.append(img.size[0])\n",
    "            \n",
    "            if img.size[0] != img.size[1]:\n",
    "                print(file_path, img.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the images are square, this makes it easier to investigate their image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Smallest dimension: {min(image_sizes)}\")\n",
    "\n",
    "# Plotting\n",
    "sns.displot(image_sizes)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin resizing images, let's have a look at the general statistics of how many samples are in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_counts():\n",
    "    class_counts = {}\n",
    "    \n",
    "    for subdir in glob.glob(os.path.join(DIR, '*')):\n",
    "        file_count = len(glob.glob(os.path.join(subdir, '*')))\n",
    "        class_counts[subdir.split('/')[-1]] = file_count\n",
    "\n",
    "    return pd.DataFrame.from_dict(class_counts, orient='index', columns=['Count'])\n",
    "\n",
    "df_class_counts = get_class_counts() \n",
    "print(df_class_counts.describe([0.05, 0.25, 0.75, 0.95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the graph, the images are not all the same size. This will cause issues when we try to train the model, so we need to resize all the images to the same size. Additionally one of the images is only 3x3 which is way too small to be useful, so we will enforce a minimum image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_IMAGE_SIZE = 20\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "# Iterate through all the images and resize to a fixed size\n",
    "for subdir, dirs, images in os.walk(DIR):\n",
    "    for image in images:\n",
    "        file_path = os.path.join(subdir, image)\n",
    "        with Image.open(file_path) as img:\n",
    "            current_size = img.size[0]\n",
    "            if current_size < MIN_IMAGE_SIZE:\n",
    "                os.remove(file_path)\n",
    "                continue\n",
    "            \n",
    "            resized_img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "            resized_img.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check how many images we have in each class and see how balanced the classes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_counts = get_class_counts() \n",
    "print(df_class_counts.describe([0.05, 0.25, 0.75, 0.95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the classes are fairly balanced, let's quickly have a look at the slight imbalance in the classes.\n",
    "We can arbitrarily choose a balance metric such as outside the range of 2 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_counts = get_class_counts() \n",
    "\n",
    "mean = df_class_counts['Count'].mean()\n",
    "std = df_class_counts['Count'].std()\n",
    "threshold = 2 * std\n",
    "\n",
    "outlier_counts = df_class_counts[np.abs(df_class_counts['Count'] - mean) > threshold]\n",
    "print(outlier_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the imbalance is minimal. For simplicity we will balance the classes by removing the excess images from the classes with more images than the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_count = df_class_counts['Count'].min()\n",
    "SAMPLES_PER_CLASS = minimum_count - (minimum_count % 10)\n",
    "SAMPLES_PER_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look some examples of the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get list of all .png images in the directory and its subdirectories\n",
    "images = glob.glob(os.path.join(DIR, '**', '*.png'), recursive=True)\n",
    "\n",
    "# Randomly select num_images images\n",
    "random_images = random.sample(images, 4)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        img_path = random_images[2 * i + j]\n",
    "        img = Image.open(img_path)\n",
    "        img = ImageOps.invert(img)\n",
    "        axs[i][j].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Array Conversion\n",
    "\n",
    "Now we can convert all the images into one single numpy array with the corresponding labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(DIR):\n",
    "    if not files:\n",
    "        continue\n",
    "    \n",
    "    for i in range(SAMPLES_PER_CLASS):\n",
    "        file = files[i]\n",
    "        \n",
    "        file_path = os.path.join(subdir, file)\n",
    "        label = subdir.split('/')[-1]\n",
    "\n",
    "        img = Image.open(file_path)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        image_list.append(img_array)\n",
    "        label_list.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert the python lists into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = np.array(image_list)\n",
    "image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = np.array(label_list)\n",
    "label_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can save the numpy arrays to the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('images.npy', image_list)\n",
    "np.save('labels.npy', label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(64, 64, 1)),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(248, activation='relu')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
