{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 01:40:22.829116: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 01:40:22.830845: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 01:40:22.857943: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 01:40:22.857972: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 01:40:22.857990: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 01:40:22.862842: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 01:40:22.863824: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 01:40:23.478084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, RandomTranslation, RandomRotation, RandomFlip\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('images.npy')\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = to_categorical(encoder.fit_transform(labels))\n",
    "\n",
    "NUM_CLASSES = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getCNNModel():\n",
    "    model = Sequential([\n",
    "        Input(shape=(64, 64, 1)),\n",
    "        # RandomTranslation(0.1, 0.1),\n",
    "        # RandomRotation(0.5),\n",
    "        # RandomFlip(),\n",
    "        Conv2D(16, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        BatchNormalization(),   \n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        BatchNormalization(), \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        BatchNormalization(), \n",
    "        Flatten(),\n",
    "        Dense(units=256, activation='relu'),\n",
    "        BatchNormalization(), \n",
    "        Dropout(0.5),\n",
    "        Dense(units=NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_train, IMG_test, LBL_train, LBL_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/20\n",
      "365/365 [==============================] - 24s 62ms/step - loss: 4.6060 - accuracy: 0.0802 - val_loss: 3.1397 - val_accuracy: 0.2692\n",
      "Epoch 2/20\n",
      "365/365 [==============================] - 24s 67ms/step - loss: 2.9612 - accuracy: 0.2814 - val_loss: 1.8336 - val_accuracy: 0.5859\n",
      "Epoch 3/20\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 1.9421 - accuracy: 0.5014 - val_loss: 1.1968 - val_accuracy: 0.7404\n",
      "Epoch 4/20\n",
      "365/365 [==============================] - 23s 64ms/step - loss: 1.3882 - accuracy: 0.6377 - val_loss: 0.8641 - val_accuracy: 0.8162\n",
      "Epoch 5/20\n",
      "365/365 [==============================] - 24s 66ms/step - loss: 1.0671 - accuracy: 0.7230 - val_loss: 0.6856 - val_accuracy: 0.8537\n",
      "Epoch 6/20\n",
      "365/365 [==============================] - 32s 89ms/step - loss: 0.8675 - accuracy: 0.7718 - val_loss: 0.5704 - val_accuracy: 0.8747\n",
      "Epoch 7/20\n",
      "365/365 [==============================] - 21s 58ms/step - loss: 0.7242 - accuracy: 0.8106 - val_loss: 0.4813 - val_accuracy: 0.8887\n",
      "Epoch 8/20\n",
      "365/365 [==============================] - 22s 60ms/step - loss: 0.6189 - accuracy: 0.8373 - val_loss: 0.4234 - val_accuracy: 0.9018\n",
      "Epoch 9/20\n",
      "365/365 [==============================] - 22s 62ms/step - loss: 0.5309 - accuracy: 0.8595 - val_loss: 0.3823 - val_accuracy: 0.9098\n",
      "Epoch 10/20\n",
      "365/365 [==============================] - 23s 62ms/step - loss: 0.4695 - accuracy: 0.8765 - val_loss: 0.3411 - val_accuracy: 0.9188\n",
      "Epoch 11/20\n",
      "365/365 [==============================] - 23s 62ms/step - loss: 0.4156 - accuracy: 0.8906 - val_loss: 0.3146 - val_accuracy: 0.9223\n",
      "Epoch 12/20\n",
      "365/365 [==============================] - 23s 63ms/step - loss: 0.3709 - accuracy: 0.9034 - val_loss: 0.2967 - val_accuracy: 0.9270\n",
      "Epoch 13/20\n",
      "365/365 [==============================] - 23s 63ms/step - loss: 0.3372 - accuracy: 0.9112 - val_loss: 0.2740 - val_accuracy: 0.9297\n",
      "Epoch 14/20\n",
      "365/365 [==============================] - 23s 63ms/step - loss: 0.3067 - accuracy: 0.9183 - val_loss: 0.2560 - val_accuracy: 0.9333\n",
      "Epoch 15/20\n",
      "365/365 [==============================] - 23s 62ms/step - loss: 0.2776 - accuracy: 0.9268 - val_loss: 0.2413 - val_accuracy: 0.9370\n",
      "Epoch 16/20\n",
      "365/365 [==============================] - 22s 61ms/step - loss: 0.2538 - accuracy: 0.9327 - val_loss: 0.2580 - val_accuracy: 0.9324\n",
      "Epoch 17/20\n",
      "365/365 [==============================] - 22s 61ms/step - loss: 0.2278 - accuracy: 0.9400 - val_loss: 0.2227 - val_accuracy: 0.9414\n",
      "Epoch 18/20\n",
      "365/365 [==============================] - 22s 61ms/step - loss: 0.2133 - accuracy: 0.9431 - val_loss: 0.2099 - val_accuracy: 0.9438\n",
      "Epoch 19/20\n",
      "365/365 [==============================] - 22s 61ms/step - loss: 0.1948 - accuracy: 0.9477 - val_loss: 0.2061 - val_accuracy: 0.9432\n",
      "Epoch 20/20\n",
      "365/365 [==============================] - 26s 72ms/step - loss: 0.1808 - accuracy: 0.9524 - val_loss: 0.2022 - val_accuracy: 0.9462\n",
      "Fold 2/5\n",
      "Epoch 1/20\n",
      "365/365 [==============================] - 24s 64ms/step - loss: 4.3686 - accuracy: 0.1055 - val_loss: 2.6893 - val_accuracy: 0.3560\n",
      "Epoch 2/20\n",
      " 50/365 [===>..........................] - ETA: 19s - loss: 3.1063 - accuracy: 0.2475"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m train_data \u001b[38;5;241m=\u001b[39m (IMG_train[train_idxs], LBL_train[train_idxs])\n\u001b[1;32m     17\u001b[0m val_data\u001b[38;5;241m=\u001b[39m(IMG_train[val_idxs], LBL_train[val_idxs])\n\u001b[0;32m---> 19\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m best_val_acc:\n\u001b[1;32m     21\u001b[0m     best_val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1774\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1772\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1774\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   1775\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m         ):\n\u001b[1;32m   1782\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[1;32m   1416\u001b[0m )\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:687\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    686\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    689\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:814\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \n\u001b[1;32m    807\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 814\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:793\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    791\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 793\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    796\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    797\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[1;32m    799\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[1;32m    800\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    801\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:783\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    782\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 783\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:533\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    536\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "best_val_acc = -1\n",
    "best_model = None\n",
    "\n",
    "for i, (train_idxs, val_idxs) in enumerate(kfold.split(IMG_train, LBL_train)):\n",
    "    print(f\"Fold {i + 1}/{k}\")\n",
    "    \n",
    "    model = getCNNModel()\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    train_data = (IMG_train[train_idxs], LBL_train[train_idxs])\n",
    "    val_data=(IMG_train[val_idxs], LBL_train[val_idxs])\n",
    "\n",
    "    history = model.fit(*train_data, validation_data=val_data, batch_size=128, epochs=20)\n",
    "    if history.history['val_accuracy'][-1] > best_val_acc:\n",
    "        best_val_acc = history.history['val_accuracy'][-1]\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miikey_lol/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "best_model.save('best_cnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "cnn_model: Sequential = load_model('best_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_output = cnn_model.layers[-4].output \n",
    "feature_model = Model(inputs=cnn_model.input, outputs=feature_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1825/1825 [==============================] - 14s 7ms/step\n",
      "457/457 [==============================] - 3s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "train_features = feature_model.predict(IMG_train)\n",
    "test_features = feature_model.predict(IMG_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58400, 256)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from one-hot encoding to integer encoding\n",
    "LBL_train_int = np.argmax(LBL_train, axis=1)\n",
    "LBL_test_int = np.argmax(LBL_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from integer encoding back to original labels\n",
    "LBL_train_original = encoder.inverse_transform(LBL_train_int)\n",
    "LBL_test_original = encoder.inverse_transform(LBL_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save train and test features to a single file\n",
    "np.savez('data.npz',\n",
    "         train_features=train_features,\n",
    "         test_features=test_features,\n",
    "         train_labels=LBL_train_original,\n",
    "         test_labels=LBL_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('features.npz')\n",
    "train_features = data['train_features']\n",
    "test_features = data['test_features']\n",
    "train_labels = data['train_labels']\n",
    "test_labels = data['test_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miikey_lol/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=400)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=400)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=400)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regressor = LogisticRegression(solver='lbfgs', max_iter=400)\n",
    "logistic_regressor.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_regressor.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           一       1.00      0.99      1.00       125\n",
      "           七       0.96      0.96      0.96       138\n",
      "           上       0.97      0.99      0.98       155\n",
      "           中       0.95      0.94      0.94       143\n",
      "           么       0.97      0.95      0.96       150\n",
      "           九       0.93      0.94      0.94       137\n",
      "           书       0.95      0.97      0.96       151\n",
      "           买       0.94      0.96      0.95       149\n",
      "           了       0.98      0.99      0.98       136\n",
      "           些       0.95      0.98      0.97       156\n",
      "           京       0.95      0.94      0.95       149\n",
      "           人       0.96      0.99      0.98       145\n",
      "           他       0.96      0.99      0.97       153\n",
      "           们       0.99      0.97      0.98       131\n",
      "           会       0.95      0.96      0.96       168\n",
      "           作       0.93      0.91      0.92       137\n",
      "           你       0.93      0.93      0.93       137\n",
      "           候       0.96      0.99      0.98       158\n",
      "           做       0.96      0.94      0.95       151\n",
      "           六       0.92      0.94      0.93       141\n",
      "           关       0.97      0.96      0.97       156\n",
      "           兴       0.94      0.91      0.93       140\n",
      "           再       0.96      0.96      0.96       139\n",
      "           写       0.93      0.91      0.92       164\n",
      "           分       0.97      0.96      0.97       158\n",
      "           北       0.94      0.93      0.93       148\n",
      "           十       0.96      0.99      0.98       130\n",
      "           午       0.89      0.92      0.91       129\n",
      "           叫       0.97      0.96      0.96       161\n",
      "           吃       0.95      0.97      0.96       145\n",
      "           同       0.92      0.91      0.92       161\n",
      "           后       0.88      0.92      0.90       133\n",
      "           听       0.92      0.95      0.93       118\n",
      "           呢       0.98      0.99      0.99       152\n",
      "           和       0.95      0.97      0.96       143\n",
      "           商       0.92      0.87      0.90       141\n",
      "           喂       0.98      0.99      0.98       147\n",
      "           喜       0.98      0.99      0.98       145\n",
      "           喝       0.98      0.98      0.98       130\n",
      "           在       0.97      0.94      0.96       158\n",
      "           坐       0.95      0.93      0.94       152\n",
      "           块       0.96      0.97      0.96       152\n",
      "           多       0.95      0.90      0.93       157\n",
      "           好       0.89      0.90      0.89       146\n",
      "           妈       0.89      0.95      0.92       149\n",
      "           姐       0.95      0.94      0.94       141\n",
      "           子       0.95      0.94      0.95       153\n",
      "           字       0.94      0.92      0.93       146\n",
      "           少       0.97      0.98      0.98       157\n",
      "           工       0.97      0.99      0.98       142\n",
      "           师       0.99      0.97      0.98       146\n",
      "           年       0.84      0.88      0.86       134\n",
      "           店       0.97      0.94      0.96       161\n",
      "           打       0.98      0.98      0.98       128\n",
      "           日       0.89      0.87      0.88       156\n",
      "           明       0.94      0.94      0.94       151\n",
      "           昨       0.96      0.95      0.96       153\n",
      "           是       0.96      0.94      0.95       166\n",
      "           月       0.84      0.88      0.86       156\n",
      "           有       0.95      0.97      0.96       135\n",
      "           机       0.97      0.99      0.98       135\n",
      "           杯       0.96      0.96      0.96       156\n",
      "           果       0.93      0.96      0.94       134\n",
      "           校       0.97      0.94      0.96       161\n",
      "           桌       0.95      0.96      0.96       150\n",
      "           椅       0.95      0.97      0.96       150\n",
      "           欢       0.93      0.97      0.95       146\n",
      "           气       0.97      0.91      0.94       140\n",
      "           水       0.94      0.92      0.93       137\n",
      "           汉       0.92      0.91      0.91       128\n",
      "           没       0.89      0.93      0.91       153\n",
      "           漂       0.98      0.97      0.98       131\n",
      "           火       0.97      0.97      0.97       149\n",
      "           点       0.93      0.93      0.93       154\n",
      "           狗       0.97      0.96      0.97       150\n",
      "           猫       0.98      0.95      0.96       171\n",
      "           生       0.91      0.89      0.90       137\n",
      "           电       0.95      0.94      0.95       160\n",
      "           租       0.95      0.94      0.94       142\n",
      "           站       0.96      0.94      0.95       145\n",
      "           能       0.96      0.95      0.95       157\n",
      "           苹       0.93      0.95      0.94       150\n",
      "           菜       0.97      0.91      0.94       140\n",
      "           视       0.95      0.94      0.95       148\n",
      "           识       0.91      0.92      0.91       134\n",
      "           话       0.90      0.91      0.91       148\n",
      "           语       0.94      0.91      0.93       152\n",
      "           说       0.93      0.90      0.91       142\n",
      "           读       0.99      0.94      0.96       146\n",
      "           谁       0.97      0.97      0.97       151\n",
      "           谢       0.98      0.98      0.98       128\n",
      "           起       0.97      0.97      0.97       131\n",
      "           车       0.90      0.93      0.91       138\n",
      "           那       0.97      0.96      0.96       148\n",
      "           都       0.97      0.96      0.97       155\n",
      "           里       0.95      0.93      0.94       129\n",
      "           钟       0.98      0.97      0.97       149\n",
      "           雨       0.95      0.97      0.96       142\n",
      "           零       0.97      0.98      0.98       149\n",
      "           高       0.86      0.92      0.89       145\n",
      "\n",
      "    accuracy                           0.95     14600\n",
      "   macro avg       0.95      0.95      0.95     14600\n",
      "weighted avg       0.95      0.95      0.95     14600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(test_labels, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create an instance of the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test data\n",
    "knn_predictions = knn.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           一       1.00      1.00      1.00       125\n",
      "           七       0.91      0.97      0.94       138\n",
      "           上       0.96      0.98      0.97       155\n",
      "           中       0.92      0.98      0.95       143\n",
      "           么       0.87      0.97      0.92       150\n",
      "           九       0.92      0.95      0.94       137\n",
      "           书       0.96      0.96      0.96       151\n",
      "           买       0.95      0.94      0.95       149\n",
      "           了       0.94      0.99      0.96       136\n",
      "           些       0.93      0.97      0.95       156\n",
      "           京       0.94      0.95      0.95       149\n",
      "           人       0.94      0.99      0.96       145\n",
      "           他       0.95      0.99      0.97       153\n",
      "           们       0.98      0.98      0.98       131\n",
      "           会       0.93      0.98      0.96       168\n",
      "           作       0.88      0.91      0.90       137\n",
      "           你       0.92      0.94      0.93       137\n",
      "           候       0.95      0.96      0.95       158\n",
      "           做       0.89      0.98      0.93       151\n",
      "           六       0.92      0.94      0.93       141\n",
      "           关       0.92      0.99      0.95       156\n",
      "           兴       0.98      0.89      0.94       140\n",
      "           再       0.97      0.93      0.95       139\n",
      "           写       0.94      0.94      0.94       164\n",
      "           分       0.96      0.95      0.96       158\n",
      "           北       0.90      0.93      0.91       148\n",
      "           十       0.98      1.00      0.99       130\n",
      "           午       0.82      0.94      0.87       129\n",
      "           叫       0.92      0.99      0.95       161\n",
      "           吃       0.95      0.97      0.96       145\n",
      "           同       0.88      0.91      0.89       161\n",
      "           后       0.92      0.91      0.91       133\n",
      "           听       0.90      0.95      0.93       118\n",
      "           呢       0.95      0.97      0.96       152\n",
      "           和       0.95      0.94      0.94       143\n",
      "           商       0.92      0.87      0.89       141\n",
      "           喂       0.99      0.97      0.98       147\n",
      "           喜       0.92      0.98      0.95       145\n",
      "           喝       0.95      0.96      0.96       130\n",
      "           在       0.96      0.94      0.95       158\n",
      "           坐       0.89      0.91      0.90       152\n",
      "           块       0.94      0.97      0.95       152\n",
      "           多       0.90      0.94      0.92       157\n",
      "           好       0.88      0.87      0.88       146\n",
      "           妈       0.90      0.91      0.90       149\n",
      "           姐       0.92      0.92      0.92       141\n",
      "           子       0.95      0.92      0.94       153\n",
      "           字       0.95      0.90      0.92       146\n",
      "           少       0.96      0.99      0.97       157\n",
      "           工       0.97      1.00      0.98       142\n",
      "           师       0.99      0.97      0.98       146\n",
      "           年       0.88      0.90      0.89       134\n",
      "           店       0.94      0.94      0.94       161\n",
      "           打       0.97      0.99      0.98       128\n",
      "           日       0.88      0.86      0.87       156\n",
      "           明       0.96      0.91      0.93       151\n",
      "           昨       0.95      0.93      0.94       153\n",
      "           是       0.94      0.93      0.94       166\n",
      "           月       0.84      0.83      0.83       156\n",
      "           有       0.97      0.96      0.96       135\n",
      "           机       0.94      0.99      0.96       135\n",
      "           杯       0.98      0.94      0.96       156\n",
      "           果       0.90      0.97      0.94       134\n",
      "           校       0.98      0.94      0.96       161\n",
      "           桌       0.96      0.93      0.95       150\n",
      "           椅       0.93      0.98      0.95       150\n",
      "           欢       0.95      0.96      0.96       146\n",
      "           气       0.97      0.91      0.94       140\n",
      "           水       0.94      0.88      0.91       137\n",
      "           汉       0.93      0.95      0.94       128\n",
      "           没       0.93      0.90      0.92       153\n",
      "           漂       1.00      0.98      0.99       131\n",
      "           火       0.95      0.95      0.95       149\n",
      "           点       0.97      0.94      0.95       154\n",
      "           狗       0.99      0.95      0.97       150\n",
      "           猫       0.98      0.95      0.96       171\n",
      "           生       0.89      0.86      0.88       137\n",
      "           电       0.99      0.92      0.95       160\n",
      "           租       0.94      0.89      0.92       142\n",
      "           站       0.96      0.93      0.94       145\n",
      "           能       0.99      0.94      0.96       157\n",
      "           苹       0.93      0.95      0.94       150\n",
      "           菜       0.96      0.92      0.94       140\n",
      "           视       0.98      0.91      0.94       148\n",
      "           识       0.94      0.90      0.92       134\n",
      "           话       0.95      0.86      0.90       148\n",
      "           语       0.91      0.89      0.90       152\n",
      "           说       0.96      0.87      0.91       142\n",
      "           读       0.98      0.92      0.95       146\n",
      "           谁       0.99      0.97      0.98       151\n",
      "           谢       0.97      0.98      0.97       128\n",
      "           起       0.97      0.93      0.95       131\n",
      "           车       0.95      0.91      0.93       138\n",
      "           那       0.97      0.97      0.97       148\n",
      "           都       0.97      0.94      0.95       155\n",
      "           里       0.97      0.90      0.93       129\n",
      "           钟       0.98      0.98      0.98       149\n",
      "           雨       0.94      0.93      0.93       142\n",
      "           零       0.99      0.99      0.99       149\n",
      "           高       0.88      0.90      0.89       145\n",
      "\n",
      "    accuracy                           0.94     14600\n",
      "   macro avg       0.94      0.94      0.94     14600\n",
      "weighted avg       0.94      0.94      0.94     14600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, knn_predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "def numpy_to_image(numpy_array):\n",
    "    return Image.fromarray(numpy_array.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Get the indices of correct and wrong predictions\n",
    "correct_indices = np.where(predictions == test_labels)[0]\n",
    "wrong_indices = np.where(predictions != test_labels)[0]\n",
    "\n",
    "correct_indices = random.sample(list(correct_indices), 4)\n",
    "wrong_indices = random.sample(list(wrong_indices), 4)\n",
    "\n",
    "correct_images = [IMG_test[idx] for idx in correct_indices]\n",
    "wrong_images = [IMG_test[idx] for idx in wrong_indices]\n",
    "\n",
    "correct_pred = (correct_indices, correct_images)\n",
    "wrong_pred = (wrong_indices, wrong_images)\n",
    "\n",
    "# Set the font for the plot\n",
    "import matplotlib.font_manager as fm\n",
    "font_path = 'NotoSansCJKsc-Regular.otf'\n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "for idxs, images in (wrong_pred, ):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            idx = idxs[2 * i + j]\n",
    "            numpy_image = images[2 * i + j]\n",
    "            img = numpy_to_image(numpy_image)\n",
    "            img = ImageOps.invert(img)\n",
    "            axs[i][j].imshow(img)\n",
    "            axs[i][j].set_title(f\"Prediction: {predictions[idx]}, Actual: {LBL_test_original[idx]}\", fontproperties=prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "\n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9328082191780822\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
