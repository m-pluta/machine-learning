{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Image handling\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# CNN\n",
    "from keras.utils import to_categorical, set_random_seed\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Tuning\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducibility, we define the seed and ensure all libraries are using this seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "set_random_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we establish the directory to where our data is stored, and where we ultimately want to store our cleaned, processed data as well as any plots we generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_DIR = 'chinese-handwriting-recognition-hsk-1/chinese-handwriting/'\n",
    "\n",
    "INIT_TRAIN_DIR = os.path.join(INIT_DIR, 'CASIA-HWDB_Train/Train/')\n",
    "INIT_TEST_DIR = os.path.join(INIT_DIR, 'CASIA-HWDB_Test/Test/')\n",
    "\n",
    "DIR = 'data/'\n",
    "PLOT_DIR = 'report/img/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets have a look at how many data classes we have in the dataset. The dataset has been split into test and train already so lets check how many classes we have in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classes = os.listdir(INIT_TRAIN_DIR)\n",
    "\n",
    "if image_classes == os.listdir(INIT_TEST_DIR):\n",
    "    print('The same classes are in each folder')\n",
    "else:\n",
    "    print('The two folders contain different classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets combine the the train and test data into one directory for simplicity.\n",
    "\n",
    "We start by creating a new directory for our preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old data directory\n",
    "if os.path.exists(DIR):\n",
    "    shutil.rmtree(DIR)\n",
    "    \n",
    "# Create the new directory\n",
    "os.mkdir(DIR)\n",
    "for image_class in image_classes:\n",
    "    path = os.path.join(DIR, image_class)\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the train and test data into one directory. This is specified by the `DIR` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineDirectories():\n",
    "    for image_class in image_classes:\n",
    "        images = []\n",
    "\n",
    "        # Fetch images from train dir\n",
    "        train_path = os.path.join(INIT_TRAIN_DIR, image_class)\n",
    "        images += [os.path.join(train_path, file) for file in os.listdir(train_path)]\n",
    "\n",
    "        # Fetch images from test dir\n",
    "        test_path = os.path.join(INIT_TEST_DIR, image_class)\n",
    "        images += [os.path.join(test_path, file) for file in os.listdir(test_path)]\n",
    "\n",
    "        # Iterate over the splits and images and copy them to the data directory\n",
    "        for i, image in enumerate(images):\n",
    "            new_filename = f\"{i+1}.png\"\n",
    "            destination_path = os.path.join(DIR, image_class, new_filename)\n",
    "            shutil.copy(image, destination_path)\n",
    "            \n",
    "combineDirectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets iterate through all the images and and confirm they are all `.png` and black & white "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGrayscale():\n",
    "    # Loop through each subdirectory and file in the directory\n",
    "    for subdir, dirs, images in os.walk(DIR):\n",
    "        for image in images:\n",
    "            # Only check .png's\n",
    "            if image.lower().endswith('.png'):\n",
    "                file_path = os.path.join(subdir, image)\n",
    "\n",
    "                # Check if the channel is set to 'L' = grayscale\n",
    "                with Image.open(file_path) as img:\n",
    "                    if img.mode != 'L':\n",
    "                        print(f\"{file_path} is not grayscale.\")\n",
    "            else:\n",
    "                print(\"Not a png file: \")\n",
    "checkGrayscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's iterate through all the images and check if any have an aspect ratio that is not 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAspectRatios():\n",
    "    image_sizes = []\n",
    "\n",
    "    # Iterate through all the images and check if any do not have a 1:1 aspect ratio\n",
    "    for subdir, dirs, images in os.walk(DIR):\n",
    "        for image in images:\n",
    "            file_path = os.path.join(subdir, image)\n",
    "            with Image.open(file_path) as img:\n",
    "                image_sizes.append(img.size[0])\n",
    "\n",
    "                # Both images dimensions must be the same for 1:1 ratio\n",
    "                if img.size[0] != img.size[1]:\n",
    "                    print(file_path, img.size)\n",
    "                    \n",
    "    return image_sizes\n",
    "                    \n",
    "image_sizes = checkAspectRatios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the images are square, this makes it easier to investigate their image sizes.\n",
    "\n",
    "Let's plot a distribution of all the image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Smallest dimension: {min(image_sizes)}\")\n",
    "\n",
    "# Plotting\n",
    "sns.displot(image_sizes, height=4, aspect=4/3)\n",
    "plt.xlabel('Dimension')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{PLOT_DIR}image_dimension_distribution.png\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the graph, the images are not all the same size. This will cause issues when we try to train the model, so we need to resize all the images to the same size. Additionally one of the images is only 3x3 which is way too small to be useful, so we will enforce a minimum image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MIN_IMAGE_SIZE = 20\n",
    "IMAGE_SIZE = 48\n",
    "\n",
    "def resizeImages():\n",
    "    # Iterate through all the images and resize to a fixed size\n",
    "    for subdir, dirs, images in os.walk(DIR):\n",
    "        for image in images:\n",
    "            file_path = os.path.join(subdir, image)\n",
    "            with Image.open(file_path) as img:\n",
    "                current_size = img.size[0]\n",
    "                \n",
    "                # Images too small\n",
    "                if current_size < MIN_IMAGE_SIZE:\n",
    "                    os.remove(file_path)\n",
    "                    continue\n",
    "                \n",
    "                # Only resize if not the correct size already\n",
    "                if current_size != IMAGE_SIZE:\n",
    "                    img = img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Invert the image so it looks cooler\n",
    "                img = ImageOps.invert(img)\n",
    "                img.save(file_path)\n",
    "                \n",
    "resizeImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check how many images we have in each class and see how balanced the classes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe of how many samples in each class\n",
    "def get_class_counts():\n",
    "    class_counts = {}\n",
    "    \n",
    "    for subdir in glob.glob(os.path.join(DIR, '*')):\n",
    "        file_count = len(glob.glob(os.path.join(subdir, '*')))\n",
    "        class_counts[subdir.split('/')[-1]] = file_count\n",
    "\n",
    "    return pd.DataFrame.from_dict(class_counts, orient='index', columns=['Count'])\n",
    "\n",
    "df_class_counts = get_class_counts() \n",
    "\n",
    "# Plot the distribution of the class counts\n",
    "sns.displot(list(df_class_counts['Count']), height=4, aspect=4/3)\n",
    "plt.xlabel('Samples per class')\n",
    "plt.ylabel('Class count')\n",
    "\n",
    "# Show and save\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{PLOT_DIR}class_imbalance.svg\")\n",
    "plt.show()\n",
    "\n",
    "# Print some more detailed statistics\n",
    "print(df_class_counts.describe([0.05, 0.25, 0.75, 0.95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the classes are fairly balanced, let's quickly have a look at the slight imbalance in the classes.\n",
    "We can arbitrarily choose a balance metric such as outside the range of 2 standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_class_counts['Count'].mean()\n",
    "std = df_class_counts['Count'].std()\n",
    "threshold = 2 * std\n",
    "\n",
    "outlier_counts = df_class_counts[np.abs(df_class_counts['Count'] - mean) > threshold]\n",
    "print(outlier_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the imbalance is minimal. Because of this, we will not be using any class balancing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look some examples of the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all .png images in the directory and its subdirectories\n",
    "images = glob.glob(os.path.join(DIR, '**', '*.png'), recursive=True)\n",
    "\n",
    "# Randomly select 4 images\n",
    "random_images = random.sample(images, 4)\n",
    "\n",
    "# Create the figure\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "# Populate the figure\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        img_path = random_images[2 * i + j]\n",
    "        img = Image.open(img_path)\n",
    "        axs[i][j].imshow(img)\n",
    "        # axs[i][j].set_title(f\"Character: {img_path.split('/')[1]}\", fontproperties=prop, fontsize = 12)\n",
    "\n",
    "# Show and save the figure\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{PLOT_DIR}example_images.png\", dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Array Conversion\n",
    "\n",
    "Now we can convert all the images into one single numpy array with the corresponding labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterate over each image\n",
    "    for image_class in classes:\n",
    "        path = os.path.join(DIR, image_class)\n",
    "        for image in os.listdir(path):\n",
    "            image_path = os.path.join(path, image)\n",
    "\n",
    "            # Open the image and convert it to a numpy array\n",
    "            img = Image.open(image_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            images.append(img_array)\n",
    "            labels.append(image_class)\n",
    "            \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images, labels = get_numpy_data(image_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can save the numpy arrays to the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('images.npy', images)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images scale the values between 0 and 1\n",
    "images = np.load('images.npy').astype(\"float32\") / 255\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=SEED, stratify=labels)\n",
    "\n",
    "# Define the label encoder\n",
    "encoder = LabelEncoder().fit(np.concatenate((y_train, y_test)))\n",
    "\n",
    "def encode_labels(encoder: LabelEncoder, labels):\n",
    "    integer_labels = encoder.transform(labels)\n",
    "    ohe_labels = to_categorical(integer_labels)\n",
    "    return integer_labels, ohe_labels\n",
    "\n",
    "# Encode the labels into integeres and one-hot-encoded vectors\n",
    "y_train_int, y_train_ohe = encode_labels(encoder, y_train)\n",
    "y_test_int, y_test_ohe = encode_labels(encoder, y_test)\n",
    "\n",
    "NUM_CLASSES = y_train_ohe.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view some general information about the generated input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train_int.shape)\n",
    "print(y_test_int.shape)\n",
    "\n",
    "print(y_train_ohe.shape)\n",
    "print(y_test_ohe.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define the architecture of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCNNModel(hp):\n",
    "    model = Sequential([\n",
    "        Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1)),\n",
    "        \n",
    "        # Main convolution layer 1\n",
    "        Conv2D(hp.Int('conv_1_filters', min_value=8, max_value=32, step=8), kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)),\n",
    "        \n",
    "        # Main convolution layer 2\n",
    "        Conv2D(hp.Int('conv_2_filters', min_value=16, max_value=64, step=16), kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)),\n",
    "        \n",
    "        # Main convolution layer 3\n",
    "        Conv2D(hp.Int('conv_3_filters', min_value=32, max_value=128, step=32), kernel_size=2, activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(hp.Float('dropout_3', min_value=0.0, max_value=0.5, step=0.1)),\n",
    "        \n",
    "        # Classification layer\n",
    "        Flatten(),\n",
    "        Dense(units=hp.Int('dense_units', min_value=128, max_value=1024, step=128), activation='relu'),\n",
    "        Dropout(hp.Float('dropout_4', min_value=0.0, max_value=0.7, step=0.1)),\n",
    "        Dense(units=NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model using the Adam optimizer\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            hp.Choice('learning_rate', values=[1e-2, 5e-3, 1e-3, 5e-4, 1e-4])),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the hyperparameter tuner and start the search for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tuner which optimizes the validation accuracy\n",
    "tuner = kt.Hyperband(\n",
    "    getCNNModel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,\n",
    "    directory='hyperband',\n",
    "    project_name='cnn_tuning20')\n",
    "\n",
    "# Early stopping callback which detects bad configurations early\n",
    "stop_early = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5)\n",
    "\n",
    "# Checkpoint callback to save the best model to a file for later use\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "# Begin the hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, y_train_ohe,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[stop_early, checkpoint],\n",
    "    epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at what the best hyperparameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best hyperparameters: {best_hps.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the model is not overfitting, we will perform cross validation on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "fold_history = []\n",
    "\n",
    "for i, (train_idxs, val_idxs) in enumerate(kfold.split(X_train, y_train_ohe)):\n",
    "    print(f\"Fold {i + 1}/{k}\")\n",
    "    \n",
    "    model = getCNNModel(best_hps)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train[train_idxs],\n",
    "        y_train_ohe[train_idxs],\n",
    "        validation_data=(X_train[val_idxs], y_train_ohe[val_idxs]),\n",
    "        epochs=30,\n",
    "        batch_size=64\n",
    "    )\n",
    "    val_acc_per_epoch = history.history['val_accuracy']\n",
    "    best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "    print(f'Best epoch: {best_epoch}, Val_accuracy: {max(val_acc_per_epoch)}')\n",
    "    fold_history.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data collected from the cross validation, we can plot the accuracy and loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(fold_history[0].history)\n",
    "\n",
    "for i, history in enumerate(fold_history[1:]):\n",
    "    df = pd.concat([df, pd.DataFrame(history.history)])\n",
    "\n",
    "df_long = df.reset_index().melt(id_vars='index', value_vars=['accuracy', 'val_accuracy', 'loss', 'val_loss'])\n",
    "\n",
    "df_long.rename(columns={'index': 'Epoch', 'variable': 'Metric', 'value': 'Value'}, inplace=True)\n",
    "df_long['Epoch'] = df_long['Epoch'] + 1\n",
    "\n",
    "df_accuracy = df_long[df_long['Metric'].isin(['accuracy', 'val_accuracy'])]\n",
    "df_loss = df_long[df_long['Metric'].isin(['loss', 'val_loss'])]\n",
    "\n",
    "df_accuracy = df_accuracy.replace({'val_accuracy': 'Validation', 'accuracy': 'Training'})\n",
    "df_loss = df_loss.replace({'val_loss': 'Validation', 'loss': 'Training'})\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(data=df_accuracy, x='Epoch', y='Value', hue='Metric', errorbar='sd', ax=axs[0])\n",
    "sns.lineplot(data=df_loss, x='Epoch', y='Value', hue='Metric', errorbar='sd', ax=axs[1])\n",
    "\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[0].legend(title=None)\n",
    "axs[1].legend(title=None)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.savefig(f\"{PLOT_DIR}train_val_cnn.png\", dpi=2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform feature extraction, we will use the model we trained in the previous section but we will remove the all the fully connected classification layers to ensure we are only getting the feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = load_model('best_model.h5')\n",
    "feature_model = Model(inputs=full_model.input, outputs=full_model.layers[-4].output)\n",
    "\n",
    "train_features = feature_model.predict(X_train)\n",
    "test_features = feature_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the shapes of the input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search kNN Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the parameter grid we want to search through.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [*range(5, 20, 1)],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can define the grid search and start the search for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "knn_grid_search.fit(train_features, y_train_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what the best hyperparameters found were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", knn_grid_search.best_params_)\n",
    "print(\"Best score:\", knn_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some basic analysis we can calculate the accuracy and f1 score of the kNN model w.r.t the value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "accuracys = []\n",
    "\n",
    "for i in range(2, 50, 1):\n",
    "    knn = KNeighborsClassifier(metric='euclidean', weights='distance', n_neighbors=i, n_jobs=-1)\n",
    "\n",
    "    knn.fit(train_features, y_train)\n",
    "    knn_predictions = knn.predict(test_features)\n",
    "    \n",
    "    accuracys.append(accuracy_score(y_test, knn_predictions))\n",
    "    f1s.append(f1_score(y_test, knn_predictions, average='weighted'))\n",
    "    \n",
    "    print(f\"k={i}, {accuracys[-1]}, {f1s[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 1\n",
    "k_values = range(2, 50, STEP)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(k_values, f1s[::STEP])\n",
    "ax1.set_xlabel('k')\n",
    "ax1.set_ylabel('F1 Score')\n",
    "\n",
    "ax2.plot(k_values, accuracys[::STEP])\n",
    "ax2.set_xlabel('k')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Logistic Regression Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to how we grid-searched the kNN model, we will grid-search the logistic regression model.\n",
    "\n",
    "However, in the case of logistic regression, certain solvers dont allow certain other hyperparameters to be adjusted. For example, the `liblinear` solver does not allow the `l1_ratio` hyperparameter to be adjusted. Because of this, we need to define a different parameter grid for each solver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [10, 5, 1, 0.5, 0.1],\n",
    "        'l1_ratio': [0.25, 0.5, 0.75],\n",
    "        'multi_class': ['multinomial']},\n",
    "    {\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['l1', 'l2', 'none'],\n",
    "        'C': [10, 5, 1, 0.5, 0.1],\n",
    "        'multi_class': ['multinomial']},\n",
    "    {\n",
    "        'solver': ['sag', 'lbfgs', 'newton-cg'],\n",
    "        'penalty': ['l2', 'none'],\n",
    "        'C': [10, 5, 1, 0.5, 0.1],\n",
    "        'multi_class': ['multinomial']}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the grid search and start the search for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=400,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED)\n",
    "\n",
    "log_grid_search = GridSearchCV(logistic_regressor, param_grid, cv=5, scoring='accuracy')\n",
    "log_grid_search.fit(train_features, y_train_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what the best hyperparameters found were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", log_grid_search.best_params_)\n",
    "print(\"Best score:\", log_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print out a classification report of the predicted values from the logistic regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = log_grid_search.best_estimator_\n",
    "log_predictions = logistic_regressor.predict(test_features)\n",
    "report = classification_report(y_test, encoder.inverse_transform(log_predictions), digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite intense analysis but essentially, for the logistic regression model, we want measure the accuracy, loss, training time and inference time depending on the size of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test data is not used\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_features, y_train_int, test_size=0.2, random_state=SEED, stratify=y_train_int)\n",
    "\n",
    "# Define the kfold split\n",
    "# The train data will be split into 40 equal portions\n",
    "k = 40\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Define the optimal classifiers\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=10, weights='distance')\n",
    "lgr = LogisticRegression(C=5, multi_class='multinomial', penalty='l2', solver='lbfgs')\n",
    "\n",
    "# Arrays to store values of the metrics\n",
    "num_samples = []\n",
    "knn_accuracies = []\n",
    "lgr_accuracies = []\n",
    "knn_losses = []\n",
    "lgr_losses = []\n",
    "knn_training_times = []\n",
    "lgr_training_times = []\n",
    "knn_inference_times = []\n",
    "lgr_inference_times = []\n",
    "fitted = None\n",
    "\n",
    "# Really hacky and stupid way to train the models on increasingly more portions of the dataset. There must be a better way :(\n",
    "for i, (useless_idxs, idxs) in enumerate(kfold.split(train_images, train_labels)):\n",
    "    print(f\"Portion {i + 1}/{k}\")\n",
    "    \n",
    "    # Add portion to array which store all portions that the models have already been trained on\n",
    "    if not fitted:\n",
    "        fitted = train_images[idxs], train_labels[idxs]\n",
    "    else:\n",
    "        fitted = np.concatenate((fitted[0], train_images[idxs])), np.concatenate((fitted[1], train_labels[idxs]))\n",
    "    \n",
    "    num_samples.append(len(fitted[0]))\n",
    "    \n",
    "    # Get the training times\n",
    "    start_time = time.time()\n",
    "    knn.fit(fitted[0], fitted[1])\n",
    "    end_time = time.time()\n",
    "    knn_training_times.append(end_time - start_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lgr.fit(fitted[0], fitted[1])\n",
    "    end_time = time.time()\n",
    "    lgr_training_times.append(end_time - start_time)\n",
    "    \n",
    "    # Get the inference times\n",
    "    start_time = time.time()\n",
    "    knn.predict(val_images)\n",
    "    end_time = time.time()\n",
    "    knn_inference_times.append(end_time - start_time)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lgr.predict(val_images)\n",
    "    end_time = time.time()\n",
    "    lgr_inference_times.append(end_time - start_time)\n",
    "    \n",
    "    # Get the cross-entropy loss for each model\n",
    "    knn_probs = knn.predict_proba(val_images)\n",
    "    log_reg_probs = lgr.predict_proba(val_images)\n",
    "    knn_loss = log_loss(val_labels, knn_probs)\n",
    "    lgr_loss = log_loss(val_labels, log_reg_probs)\n",
    "    knn_losses.append(knn_loss)\n",
    "    lgr_losses.append(lgr_loss)\n",
    "    \n",
    "    # Get the accuracies\n",
    "    knn_accuracy = knn.score(val_images, val_labels)\n",
    "    lgr_accuracy = lgr.score(val_images, val_labels)\n",
    "    \n",
    "    knn_accuracies.append(knn_accuracy)\n",
    "    lgr_accuracies.append(lgr_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the results of the analysis on individual subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(9, 9))\n",
    "\n",
    "# Plot the accuracy graph\n",
    "axs[0, 0].plot(np.array(num_samples) / 1000, knn_accuracies)\n",
    "axs[0, 0].plot(np.array(num_samples) / 1000, lgr_accuracies)\n",
    "axs[0, 0].set_title('Validation Accuracy')\n",
    "axs[0, 0].set_xlabel('Number of Samples (1000s)')\n",
    "axs[0, 0].set_ylabel('Accuracy')\n",
    "axs[0, 0].set_ylim((0.55, 1))\n",
    "axs[0, 0].legend(['kNN', 'Logistic Regression'], loc='upper left')\n",
    "\n",
    "# Plot the loss graph\n",
    "axs[0, 1].plot(np.array(num_samples) / 1000, knn_losses)\n",
    "axs[0, 1].plot(np.array(num_samples) / 1000, lgr_losses)\n",
    "axs[0, 1].set_title('Cross-entropy (Logistic) Loss')\n",
    "axs[0, 1].set_xlabel('Number of Samples (1000s)')\n",
    "axs[0, 1].set_ylabel('Loss')\n",
    "axs[0, 1].legend(['kNN', 'Logistic Regression'])\n",
    "\n",
    "# Plot the training time graph\n",
    "axs[1, 0].plot(np.array(num_samples) / 1000, np.log10(np.array(knn_training_times)))\n",
    "axs[1, 0].plot(np.array(num_samples) / 1000, np.log10(np.array(lgr_training_times)))\n",
    "axs[1, 0].set_title('Training Time')\n",
    "axs[1, 0].set_xlabel('Number of Samples (1000s)')\n",
    "axs[1, 0].set_ylabel('Training Time (s, log scale)')\n",
    "axs[1, 0].set_ylim((-3.4, 2.5))\n",
    "axs[1, 0].legend(['kNN', 'Logistic Regression'])\n",
    "\n",
    "# Plot the inference time graph\n",
    "axs[1, 1].plot(np.array(num_samples) / 1000, np.log10(np.array(knn_inference_times)))\n",
    "axs[1, 1].plot(np.array(num_samples) / 1000, np.log10(np.array(lgr_inference_times)))\n",
    "axs[1, 1].set_title('Inference Time')\n",
    "axs[1, 1].set_xlabel('Number of Samples (1000s)')\n",
    "axs[1, 1].set_ylabel('Inference Time (s, log scale)')\n",
    "axs[1, 1].set_ylim((-1.5, 1))\n",
    "axs[1, 1].legend(['kNN', 'Logistic Regression'])\n",
    "\n",
    "# Show and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{PLOT_DIR}model_eval.svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
